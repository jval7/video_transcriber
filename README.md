# Video Transcriber API üé•‚û°Ô∏èüìù

Una API robusta para transcribir archivos de audio y video a texto utilizando OpenAI Whisper, implementada con **Arquitectura Hexagonal** y principios de **Clean Code**.

## üèóÔ∏è Arquitectura

Este proyecto implementa **Arquitectura Hexagonal** (Ports & Adapters) para garantizar:

- **Separaci√≥n de responsabilidades**
- **Testabilidad**
- **Flexibilidad para cambiar implementaciones**
- **Independencia de frameworks externos**

### Estructura del Proyecto

```
app/
‚îú‚îÄ‚îÄ adapters/                    # Adaptadores (Infraestructura)
‚îÇ   ‚îú‚îÄ‚îÄ ffmpeg_audio_extraction_adapter.py
‚îÇ   ‚îî‚îÄ‚îÄ openai_transcription_adapter.py
‚îú‚îÄ‚îÄ config/                      # Configuraci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ logging.py
‚îú‚îÄ‚îÄ entrypoints/                 # Puntos de entrada (Controllers)
‚îÇ   ‚îú‚îÄ‚îÄ dtos.py
‚îÇ   ‚îî‚îÄ‚îÄ fastapi_app.py
‚îú‚îÄ‚îÄ service/                     # L√≥gica de negocio (Dominio)
‚îÇ   ‚îî‚îÄ‚îÄ manager.py
‚îú‚îÄ‚îÄ ports.py                     # Puertos (Interfaces)
‚îú‚îÄ‚îÄ bootstrap.py                 # Inyecci√≥n de dependencias
‚îî‚îÄ‚îÄ config.py                    # Configuraci√≥n general
```

### Diagrama de Arquitectura

```mermaid
graph TB
    subgraph "Entrypoints (Controllers)"
        API[FastAPI App]
    end
    
    subgraph "Service Layer (Domain)"
        SM[ServiceManager]
    end
    
    subgraph "Ports (Interfaces)"
        TS[TranscriptionService]
        AES[AudioExtractionService]
    end
    
    subgraph "Adapters (Infrastructure)"
        OAI[OpenAI Adapter]
        FFM[FFmpeg Adapter]
    end
    
    subgraph "External Services"
        OPENAI[OpenAI Whisper API]
        FFMPEG[FFmpeg Binary]
    end
    
    API --> SM
    SM --> TS
    TS -.-> OAI
    OAI --> AES
    AES -.-> FFM
    OAI --> OPENAI
    FFM --> FFMPEG
```

## üîå Puertos (Interfaces)

### TranscriptionService
Puerto principal para servicios de transcripci√≥n:

```python
class TranscriptionService(ABC):
    @abstractmethod
    async def transcribe_from_upload(self, uploaded_file: UploadFile, model: str = "whisper-1") -> str:
        """Transcribe un archivo subido (audio o video) a texto."""
        pass
```

### AudioExtractionService
Puerto para servicios de extracci√≥n de audio:

```python
class AudioExtractionService(ABC):
    @abstractmethod
    async def extract_audio_stream(self, uploaded_file: UploadFile) -> tuple[BinaryIO, str]:
        """Extrae audio de un archivo de video/audio y retorna un stream."""
        pass
```

## üîß Adaptadores Disponibles

### 1. OpenAI Transcription Adapter
**Ubicaci√≥n**: `app/adapters/openai_transcription_adapter.py`

**Responsabilidades**:
- Integraci√≥n con la API de OpenAI Whisper
- Manejo de diferentes formatos de archivo
- Procesamiento de archivos de video (extrae audio autom√°ticamente)
- Gesti√≥n de errores de la API externa

**Caracter√≠sticas**:
- ‚úÖ Soporte para archivos de audio directos
- ‚úÖ Extracci√≥n autom√°tica de audio desde video
- ‚úÖ M√∫ltiples modelos de Whisper
- ‚úÖ Manejo robusto de errores
- ‚úÖ Logging estructurado

### 2. FFmpeg Audio Extraction Adapter
**Ubicaci√≥n**: `app/adapters/ffmpeg_audio_extraction_adapter.py`

**Responsabilidades**:
- Extracci√≥n de audio desde archivos de video
- Conversi√≥n a formatos compatibles con OpenAI
- Optimizaci√≥n de calidad y tama√±o

**Caracter√≠sticas**:
- ‚úÖ Extracci√≥n de audio en formato WAV
- ‚úÖ Configuraci√≥n optimizada para transcripci√≥n
- ‚úÖ Manejo de m√∫ltiples formatos de video
- ‚úÖ Procesamiento en memoria (sin archivos temporales)
- ‚úÖ Validaci√≥n de archivos de entrada

## üåê API Endpoints

### POST `/transcribe`
Transcribe archivos de audio o video a texto.

**Par√°metros**:
- `file` (form-data): Archivo de audio/video a transcribir
- `model` (form-data, opcional): Modelo de OpenAI a utilizar (default: "whisper-1")

**Formatos soportados**:
- **Audio**: MP3, WAV, M4A, FLAC, OGG
- **Video**: MP4, AVI, MOV, MKV, WEBM

**Respuesta exitosa** (200):
```json
{
  "transcription": "Texto transcrito del archivo...",
  "success": true
}
```

**Respuesta de error** (400/500):
```json
{
  "success": false,
  "error": "Descripci√≥n del error"
}
```

**Ejemplo con cURL**:
```bash
curl -X POST "http://localhost:8000/transcribe" \
  -F "file=@mi_video.mp4" \
  -F "model=whisper-1"
```

### GET `/health`
Endpoint de health check para monitoreo.

**Respuesta**:
```json
{
  "status": "healthy"
}
```

## üöÄ Instalaci√≥n y Uso

### Prerrequisitos
- Python 3.12+
- FFmpeg instalado en el sistema
- Cuenta de OpenAI con API key

### 1. Clonar el repositorio
```bash
git clone https://github.com/jval7/video_transcriber.git
cd video_transcriber
```

### 2. Instalar dependencias
```bash
# Usando uv (recomendado)
uv sync

# O usando pip
pip install -r requirements.txt
```

### 3. Configurar variables de entorno
```bash
# Crear archivo .env
echo "OPENAI_API_KEY=tu_api_key_aqui" > .env
```

### 4. Ejecutar la aplicaci√≥n
```bash
# Desarrollo
python main.py

# Producci√≥n
uvicorn main:app --host 0.0.0.0 --port 8000
```

La API estar√° disponible en: `http://localhost:8000`

### 5. Documentaci√≥n interactiva
- **Swagger UI**: `http://localhost:8000/docs`
- **ReDoc**: `http://localhost:8000/redoc`

## üõ†Ô∏è Tecnolog√≠as Utilizadas

### Core
- **FastAPI**: Framework web moderno y r√°pido
- **Pydantic**: Validaci√≥n de datos y serializaci√≥n
- **OpenAI**: API de transcripci√≥n Whisper
- **FFmpeg**: Procesamiento de audio/video

### Desarrollo
- **Structlog**: Logging estructurado
- **UV**: Gesti√≥n de dependencias r√°pida
- **Python-dotenv**: Gesti√≥n de variables de entorno

### Calidad de C√≥digo
- **Black**: Formateo de c√≥digo
- **Flake8**: Linting
- **MyPy**: Type checking
- **Pylint**: An√°lisis est√°tico
- **Bandit**: An√°lisis de seguridad

## üèõÔ∏è Principios de Dise√±o

### SOLID Principles
- **S**ingle Responsibility: Cada clase tiene una responsabilidad espec√≠fica
- **O**pen/Closed: Abierto para extensi√≥n, cerrado para modificaci√≥n
- **L**iskov Substitution: Los adaptadores son intercambiables
- **I**nterface Segregation: Interfaces espec√≠ficas y cohesivas
- **D**ependency Inversion: Dependencias inyectadas a trav√©s de interfaces

### Clean Architecture
- **Independencia de frameworks**: La l√≥gica de negocio no depende de FastAPI
- **Testabilidad**: F√°cil testing mediante inyecci√≥n de dependencias
- **Independencia de UI**: La API puede ser reemplazada f√°cilmente
- **Independencia de base de datos**: Sin dependencias de almacenamiento espec√≠fico

## üß™ Testing

```bash
# Ejecutar tests
pytest

# Con coverage
pytest --cov=app tests/
```

## üìù Logging

El sistema utiliza **logging estructurado** con los siguientes niveles:
- `INFO`: Operaciones normales
- `WARNING`: Situaciones que requieren atenci√≥n
- `ERROR`: Errores que no detienen la aplicaci√≥n
- `DEBUG`: Informaci√≥n detallada para debugging

Ejemplo de log:
```json
{
  "timestamp": "2024-01-15T10:30:00Z",
  "level": "info",
  "message": "Transcripci√≥n completada exitosamente",
  "filename": "video.mp4",
  "model": "whisper-1",
  "transcription_length": 1250
}
```

## ü§ù Contribuci√≥n

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -m 'Agrega nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Ver el archivo `LICENSE` para m√°s detalles.

## üîÆ Roadmap

- [ ] Soporte para m√°s modelos de transcripci√≥n
- [ ] Cache de transcripciones
- [ ] Procesamiento en lotes
- [ ] Webhooks para notificaciones
- [ ] Interfaz web para upload de archivos
- [ ] Soporte para subt√≠tulos (SRT, VTT)
- [ ] API de traducci√≥n
- [ ] M√©tricas y monitoreo con Prometheus

---

**Desarrollado con ‚ù§Ô∏è usando Arquitectura Hexagonal y Clean Code**